{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9b1d4e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_downloader import DataDownloader\n",
    "from jwm_data_downloader import JwmDataDownloader\n",
    "\n",
    "load_dotenv()\n",
    "# Configuration\n",
    "FUNCTION_APP_URL = os.environ.get(\"MC_FUNCTION_APP_URL\")\n",
    "FUNCTION_CODE = os.environ.get(\"MC_FUNCTION_CODE\")\n",
    "downloader = DataDownloader(FUNCTION_APP_URL, FUNCTION_CODE)\n",
    "\n",
    "USERNAME = os.environ.get(\"JWM_USERNAME\")\n",
    "PASSWORD = os.environ.get(\"JWM_PASSWORD\")\n",
    "downloader_jwm = JwmDataDownloader(username=USERNAME, password=PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8023993",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Functions to convert to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fbb39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to add UTC timestamps based on date and hour columns\n",
    "def add_utc_25(\n",
    "    df: pd.DataFrame,\n",
    "    date_col: str = \"date\",\n",
    "    hour_col: str = \"hour\",\n",
    "    tz: str = \"Europe/Warsaw\",\n",
    "    out_col: str = \"Date_utc\",\n",
    "    local_col: str = \"Date_cet\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Mapuje (data, godzina 0..22/23/24) -> lokalny timestamp w tz (start godziny),\n",
    "    a następnie konwertuje do UTC. Unika duplikatów w marcu i poprawnie rozróżnia\n",
    "    podwójną 02:00 w październiku.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    # Klucz do łączenia — północ danego dnia (bez strefy)\n",
    "    out[\"_date_key\"] = pd.to_datetime(out[date_col]).dt.normalize()\n",
    "    out[hour_col] = out[hour_col].astype(int)\n",
    "    maps = []\n",
    "    for d in out[\"_date_key\"].dropna().unique():\n",
    "        # północ lokalna na początku i końcu doby\n",
    "        start = pd.Timestamp(d).tz_localize(tz)\n",
    "        end = (pd.Timestamp(d) + pd.Timedelta(days=1)).tz_localize(tz)\n",
    "        # ciąg godzin tej doby w lokalnej strefie (długość 23/24/25)\n",
    "        rng = pd.date_range(start, end, freq=\"h\", inclusive=\"left\")\n",
    "        maps.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"_date_key\": d,\n",
    "                    hour_col: np.arange(0, len(rng), dtype=int),  # zmienione z 1 na 0\n",
    "                    local_col: rng,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    mapping = (\n",
    "        pd.concat(maps, ignore_index=True)\n",
    "        if maps\n",
    "        else pd.DataFrame(columns=[\"_date_key\", hour_col, local_col])\n",
    "    )\n",
    "    # Dołączamy lokalny czas; nieistniejące kombinacje dostaną NaT\n",
    "    out = out.merge(mapping, on=[\"_date_key\", hour_col], how=\"left\")\n",
    "    # Konwersja do UTC\n",
    "    out[out_col] = out[local_col].dt.tz_convert(\"UTC\")\n",
    "    # Porządki\n",
    "    out.drop(columns=[\"_date_key\"], inplace=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "### for 15min data\n",
    "def add_utc_25_15min(\n",
    "    df: pd.DataFrame,\n",
    "    date_col: str = \"date\",\n",
    "    hour_index_col: str = \"hour_index\",\n",
    "    tz: str = \"Europe/Warsaw\",\n",
    "    out_col: str = \"Date_utc\",\n",
    "    local_col: str = \"Date_cet\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Mapuje (data, indeks godziny 0..91/95/99) -> lokalny timestamp w tz (start kwadransa),\n",
    "    a następnie konwertuje do UTC. Unika duplikatów w marcu i poprawnie rozróżnia\n",
    "    podwójną 02:00 w październiku.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    # Klucz do łączenia — północ danego dnia (bez strefy)\n",
    "    out[\"_date_key\"] = pd.to_datetime(out[date_col]).dt.normalize()\n",
    "    out[hour_index_col] = out[hour_index_col].astype(int)\n",
    "\n",
    "    maps = []\n",
    "    for d in out[\"_date_key\"].dropna().unique():\n",
    "        # północ lokalna na początku i końcu doby\n",
    "        start = pd.Timestamp(d).tz_localize(tz)\n",
    "        end = (pd.Timestamp(d) + pd.Timedelta(days=1)).tz_localize(tz)\n",
    "        # ciąg kwadransów tej doby w lokalnej strefie (długość 92/96/100)\n",
    "        rng = pd.date_range(start, end, freq=\"15min\", inclusive=\"left\")\n",
    "        maps.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"_date_key\": d,\n",
    "                    hour_index_col: np.arange(0, len(rng), dtype=int),\n",
    "                    local_col: rng,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    mapping = (\n",
    "        pd.concat(maps, ignore_index=True)\n",
    "        if maps\n",
    "        else pd.DataFrame(columns=[\"_date_key\", hour_index_col, local_col])\n",
    "    )\n",
    "    # Dołączamy lokalny czas; nieistniejące kombinacje dostaną NaT\n",
    "    out = out.merge(mapping, on=[\"_date_key\", hour_index_col], how=\"left\")\n",
    "    # Konwersja do UTC\n",
    "    out[out_col] = out[local_col].dt.tz_convert(\"UTC\")\n",
    "    # Porządki\n",
    "    out.drop(columns=[\"_date_key\"], inplace=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfbf32",
   "metadata": {},
   "source": [
    "# Rynek bilansujący"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2048a",
   "metadata": {},
   "source": [
    "## RB MC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d4494",
   "metadata": {},
   "source": [
    "### RB MC history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c553c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rb_mc_his\n",
    "rb_mc_his = downloader.get_csv_as_dataframe(\n",
    "    \"power\", \"pse_ceny_rozliczeniowe_2013-2024.csv\"\n",
    ")\n",
    "# rename columns\n",
    "rb_mc_his.rename(columns={\"Godzina\": \"hour\", \"Data\": \"date\"}, inplace=True)\n",
    "# replece , with . in all columns\n",
    "rb_mc_his = rb_mc_his.replace(\",\", \".\", regex=True)\n",
    "# rb_mceate date column\n",
    "rb_mc_his[\"date\"] = pd.to_datetime(rb_mc_his[\"date\"].astype(str), format=\"%Y%m%d\")\n",
    "rb_mc_his[\"bilans_price\"] = rb_mc_his[\"CRO\"]\n",
    "rb_mc_his[\"bilans_price\"] = rb_mc_his[\"bilans_price\"].astype(float)\n",
    "# hour index\n",
    "rb_mc_his[\"hour_idx\"] = rb_mc_his.groupby(\"date\").cumcount()\n",
    "## Append UTC timestamps\n",
    "rb_mc_his = add_utc_25(\n",
    "    rb_mc_his,\n",
    "    date_col=\"date\",\n",
    "    hour_col=\"hour_idx\",\n",
    "    tz=\"Europe/Warsaw\",\n",
    "    out_col=\"Date_utc\",\n",
    "    local_col=\"Date_cet\",\n",
    ")\n",
    "# add last row\n",
    "last = rb_mc_his.iloc[[-1]].copy()\n",
    "last[\"Date_utc\"] = last[\"Date_utc\"] + pd.Timedelta(hours=1)\n",
    "rb_mc_his = pd.concat([rb_mc_his, last], ignore_index=True)\n",
    "### resample to 15 min\n",
    "rb_mc_his_15 = rb_mc_his.set_index(\"Date_utc\").resample(\"15min\").ffill().reset_index()\n",
    "# cet time\n",
    "rb_mc_his_15[\"Date_cet\"] = rb_mc_his_15[\"Date_utc\"].dt.tz_convert(\"Europe/Warsaw\")\n",
    "# chouse relevant columns\n",
    "rb_mc_his_15 = rb_mc_his_15[[\"Date_utc\", \"Date_cet\", \"bilans_price\"]]\n",
    "# cut last row\n",
    "rb_mc_his_15 = rb_mc_his_15[:-1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a4923",
   "metadata": {},
   "source": [
    "### RB MC new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad42104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cr_new\n",
    "rb_mc_new = downloader.get_csv_as_dataframe(\"power\", \"pse_ceny_rozliczeniowe.csv\")\n",
    "# replece , with . in all columns\n",
    "rb_mc_new = rb_mc_new.replace(\",\", \".\", regex=True)\n",
    "# rename columns\n",
    "rb_mc_new.rename(columns={\"doba\": \"date\"}, inplace=True)\n",
    "# hour index\n",
    "rb_mc_new[\"hour_idx\"] = rb_mc_new.groupby(\"date\").cumcount()\n",
    "## Append UTC timestamps\n",
    "rb_mc_new = add_utc_25_15min(\n",
    "    rb_mc_new,\n",
    "    date_col=\"date\",\n",
    "    hour_index_col=\"hour_idx\",\n",
    "    tz=\"Europe/Warsaw\",\n",
    "    out_col=\"Date_utc\",\n",
    "    local_col=\"Date_cet\",\n",
    ")\n",
    "# rename columns\n",
    "rb_mc_new.rename(\n",
    "    columns={\"cen_rozl\": \"bilans_price\", \"source_datetime\": \"Date_of_publication_cet\"},\n",
    "    inplace=True,\n",
    ")\n",
    "# chouse relevant columns\n",
    "rb_mc_new = rb_mc_new[\n",
    "    [\"Date_utc\", \"Date_cet\", \"bilans_price\", \"Date_of_publication_cet\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880c7f0",
   "metadata": {},
   "source": [
    "### RB MC join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfd07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join cr_his and rb_mc\n",
    "rb_mc = pd.concat([rb_mc_his_15, rb_mc_new])\n",
    "# chouse time period before 2024-06-14\n",
    "rb_mc = rb_mc[rb_mc[\"Date_cet\"] < \"2024-06-14\"].copy()\n",
    "# utc time\n",
    "rb_mc[\"Date_of_publication_cet\"] = pd.to_datetime(\n",
    "    rb_mc[\"Date_of_publication_cet\"]\n",
    ").dt.tz_localize(\"Europe/Warsaw\")\n",
    "rb_mc[\"Date_of_publication_utc\"] = rb_mc[\"Date_of_publication_cet\"].dt.tz_convert(\"UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b89b4",
   "metadata": {},
   "source": [
    "## RB JWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "332375d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rb_jwm\n",
    "rb_jwm = downloader_jwm.download_as_dataframe(\"utc/regulation_prices.csv\")\n",
    "# drop irrelevant columns\n",
    "rb_jwm = rb_jwm.drop(columns=[\"Delivery end\", \"Type\", \"Date\"])\n",
    "# rename columns\n",
    "rb_jwm = rb_jwm.rename(\n",
    "    columns={\n",
    "        \"Delivery start\": \"Date_utc\",\n",
    "        \"Publication timestamp\": \"Date_of_publication_utc\",\n",
    "        \"Price\": \"bilans_price\",\n",
    "    }\n",
    ")\n",
    "# to datetime\n",
    "rb_jwm[\"Date_utc\"] = pd.to_datetime(rb_jwm[\"Date_utc\"])\n",
    "rb_jwm[\"Date_of_publication_utc\"] = pd.to_datetime(rb_jwm[\"Date_of_publication_utc\"])\n",
    "# CET time\n",
    "rb_jwm[\"Date_cet\"] = rb_jwm[\"Date_utc\"].dt.tz_convert(\"Europe/Warsaw\")\n",
    "rb_jwm[\"Date_of_publication_cet\"] = rb_jwm[\"Date_of_publication_utc\"].dt.tz_convert(\n",
    "    \"Europe/Warsaw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027e13c",
   "metadata": {},
   "source": [
    "## RB MC join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba10e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join rb_mc and rb_jwm\n",
    "rb = pd.concat([rb_mc, rb_jwm], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c7b24",
   "metadata": {},
   "source": [
    "# Fix1Fix2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe7c25",
   "metadata": {},
   "source": [
    "## MC Fix1Fix2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e654c4",
   "metadata": {},
   "source": [
    "### MC Fix1Fix2 history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba36f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fix_his\n",
    "fix_mc_his = downloader.get_csv_as_dataframe(\n",
    "    \"power\", \"electricity_prices_day_ahead_hourly_all.csv\"\n",
    ")\n",
    "# Convert the date column to datetime\n",
    "fix_mc_his[\"date\"] = pd.to_datetime(fix_mc_his[\"date\"], dayfirst=True).dt.date\n",
    "# hour index\n",
    "fix_mc_his[\"hour_idx\"] = fix_mc_his.groupby(\"date\").cumcount()\n",
    "## Append UTC timestamps\n",
    "fix_mc_his = add_utc_25(\n",
    "    fix_mc_his,\n",
    "    date_col=\"date\",\n",
    "    hour_col=\"hour_idx\",\n",
    "    tz=\"Europe/Warsaw\",\n",
    "    out_col=\"Date_utc\",\n",
    "    local_col=\"Date_cet\",\n",
    ")\n",
    "# rename columns\n",
    "fix_mc_his.rename(\n",
    "    columns={\n",
    "        \"fixing_i_price\": \"fixing1_price\",\n",
    "        \"fixing_ii_price\": \"fixing2_price\",\n",
    "        \"fixing_i_volume\": \"fixing1_volume\",\n",
    "        \"fixing_ii_volume\": \"fixing2_volume\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# drop irrelevant columns\n",
    "fix_mc_his = fix_mc_his.drop(columns=[\"date\", \"hour_idx\"])\n",
    "# chouse data before 2024-06-14\n",
    "fix_mc_his = fix_mc_his[\n",
    "    pd.to_datetime(fix_mc_his[\"Date_cet\"].dt.date) < \"2024-11-15\"\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62280757",
   "metadata": {},
   "source": [
    "### MC Fix1Fix2 new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1825a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fix_new\n",
    "fix_mc_new = downloader.get_csv_as_dataframe(\"power\", \"tge_energy.csv\")\n",
    "# date column to datetime\n",
    "fix_mc_new[\"date\"] = pd.to_datetime(fix_mc_new[\"date\"], dayfirst=True).dt.date\n",
    "# hour index\n",
    "fix_mc_new[\"hour_idx\"] = fix_mc_new.groupby(\"date\").cumcount()\n",
    "# Append UTC timestamps\n",
    "fix_mc_new = add_utc_25(\n",
    "    fix_mc_new,\n",
    "    date_col=\"date\",\n",
    "    hour_col=\"hour_idx\",\n",
    "    tz=\"Europe/Warsaw\",\n",
    "    out_col=\"Date_utc\",\n",
    "    local_col=\"Date_cet\",\n",
    ")\n",
    "# drop irrelevant columns\n",
    "fix_mc_new = fix_mc_new.drop(\n",
    "    columns=[\"date\", \"hour_idx\", \"time\", \"continuous_price\", \"continuous_volume\"]\n",
    ")\n",
    "# replace ',' with '' and change to float\n",
    "fix_mc_new[\"fixing1_price\"] = (\n",
    "    fix_mc_new[\"fixing1_price\"].str.replace(\" \", \"\").astype(float)\n",
    ")\n",
    "fix_mc_new[\"fixing2_price\"] = (\n",
    "    fix_mc_new[\"fixing2_price\"].str.replace(\" \", \"\").astype(float)\n",
    ")\n",
    "fix_mc_new[\"fixing1_volume\"] = (\n",
    "    fix_mc_new[\"fixing1_volume\"].str.replace(\" \", \"\").astype(float)\n",
    ")\n",
    "fix_mc_new[\"fixing2_volume\"] = (\n",
    "    fix_mc_new[\"fixing2_volume\"].str.replace(\" \", \"\").astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2cdf8f",
   "metadata": {},
   "source": [
    "### MC Fix1Fix2 join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e3a08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join\n",
    "fix_mc = pd.concat([fix_mc_his, fix_mc_new])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae2db2",
   "metadata": {},
   "source": [
    "## JWM Fix1Fix2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29237e1",
   "metadata": {},
   "source": [
    "### JWM FixFix2 history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3dd1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX1\n",
    "# download fix1_jwm_his\n",
    "fix1_jwm_his = downloader_jwm.download_as_dataframe(\"utc/tge_fix_1_before_2025.csv\")\n",
    "# drop duplicates based on all columns\n",
    "fix1_jwm_his.drop_duplicates(\n",
    "    subset=fix1_jwm_his.columns.tolist(), keep=\"first\", inplace=True\n",
    ")\n",
    "# rename columns\n",
    "fix1_jwm_his.rename(\n",
    "    columns={\n",
    "        \"Price\": \"fixing1_price\",\n",
    "        \"Delivery start\": \"Date_utc\",\n",
    "        \"Volume\": \"fixing1_volume\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# Date_utc to datetime\n",
    "fix1_jwm_his[\"Date_utc\"] = pd.to_datetime(fix1_jwm_his[\"Date_utc\"])\n",
    "# CET time\n",
    "fix1_jwm_his[\"Date_cet\"] = fix1_jwm_his[\"Date_utc\"].dt.tz_convert(\"Europe/Warsaw\")\n",
    "# choose relevant columns\n",
    "fix1_jwm_his = fix1_jwm_his[[\"Date_utc\", \"Date_cet\", \"fixing1_price\", \"fixing1_volume\"]]\n",
    "### FIX2\n",
    "# download fix2_jwm_his\n",
    "fix2_jwm_his = downloader_jwm.download_as_dataframe(\"utc/tge_fix_2_before_2025.csv\")\n",
    "# drop duplicates based on all columns\n",
    "fix2_jwm_his.drop_duplicates(\n",
    "    subset=fix2_jwm_his.columns.tolist(), keep=\"first\", inplace=True\n",
    ")\n",
    "# rename columns\n",
    "fix2_jwm_his.rename(\n",
    "    columns={\n",
    "        \"Price\": \"fixing2_price\",\n",
    "        \"Delivery start\": \"Date_utc\",\n",
    "        \"Volume\": \"fixing2_volume\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# Date_utc to datetime\n",
    "fix2_jwm_his[\"Date_utc\"] = pd.to_datetime(fix2_jwm_his[\"Date_utc\"])\n",
    "# CET time\n",
    "fix2_jwm_his[\"Date_cet\"] = fix2_jwm_his[\"Date_utc\"].dt.tz_convert(\"Europe/Warsaw\")\n",
    "# choose relevant columns\n",
    "fix2_jwm_his = fix2_jwm_his[[\"Date_utc\", \"Date_cet\", \"fixing2_price\", \"fixing2_volume\"]]\n",
    "# Join\n",
    "fix_jwm_his = (\n",
    "    fix1_jwm_his.set_index(\"Date_utc\")\n",
    "    .join(\n",
    "        fix2_jwm_his[[\"Date_utc\", \"fixing2_price\", \"fixing2_volume\"]].set_index(\n",
    "            \"Date_utc\"\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f67378bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in Date_utc:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_utc</th>\n",
       "      <th>Date_cet</th>\n",
       "      <th>fixing2_price</th>\n",
       "      <th>fixing2_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date_utc, Date_cet, fixing2_price, fixing2_volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show duplicates in Date_utc\n",
    "duplicates = fix2_jwm_his[fix2_jwm_his.duplicated(subset=[\"Date_utc\"], keep=False)]\n",
    "print(\"Duplicates in Date_utc:\")\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9ac65",
   "metadata": {},
   "source": [
    "### JWM FixFix2 new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2bb87c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX1\n",
    "# download fix1_jwm_new\n",
    "fix1_jwm_new = downloader_jwm.download_as_dataframe(\"utc/tge_fix_1.csv\")\n",
    "# drop duplicates based on all columns\n",
    "fix1_jwm_new.drop_duplicates(\n",
    "    subset=fix1_jwm_new.columns.tolist(), keep=\"first\", inplace=True\n",
    ")\n",
    "# rename columns\n",
    "fix1_jwm_new.rename(\n",
    "    columns={\"Price\": \"fixing1_price\", \"Delivery start\": \"Date_utc\"}, inplace=True\n",
    ")\n",
    "# ### FIX2\n",
    "# download fix2_jwm_new\n",
    "fix2_jwm_new = downloader_jwm.download_as_dataframe(\"utc/tge_fix_2.csv\")\n",
    "# drop duplicates based on all columns\n",
    "fix2_jwm_new.drop_duplicates(\n",
    "    subset=fix2_jwm_new.columns.tolist(), keep=\"first\", inplace=True\n",
    ")\n",
    "# rename columns\n",
    "fix2_jwm_new.rename(\n",
    "    columns={\"Price\": \"fixing2_price\", \"Delivery start\": \"Date_utc\"}, inplace=True\n",
    ")\n",
    "# join\n",
    "fix_jwm_new = (\n",
    "    fix1_jwm_new.set_index(\"Date_utc\")\n",
    "    .join(fix2_jwm_new[[\"Date_utc\", \"fixing2_price\"]].set_index(\"Date_utc\"))\n",
    "    .reset_index()\n",
    ")\n",
    "# CET time\n",
    "fix_jwm_new[\"Date_utc\"] = pd.to_datetime(fix_jwm_new[\"Date_utc\"])\n",
    "fix_jwm_new[\"Date_cet\"] = fix_jwm_new[\"Date_utc\"].dt.tz_convert(\"Europe/Warsaw\")\n",
    "# drop irrelevant columns\n",
    "fix_jwm_new = fix_jwm_new.drop(columns=[\"Type\", \"Date\", \"Delivery end\"]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b958632",
   "metadata": {},
   "source": [
    "### JWM FixFix2 join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f80bbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join fix_mc_his and fix_mc_new\n",
    "fix_jwm = pd.concat([fix_jwm_his, fix_jwm_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58413987",
   "metadata": {},
   "source": [
    "## Join MC and JWM Fix1Fix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c8c1b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MC Fix1Fix2 join\n",
    "# from mc choose needed date period\n",
    "fix_mc = fix_mc[(fix_mc[\"Date_cet\"] < \"2019-04-02\")].copy()\n",
    "# join mc and jwm fix1fix2\n",
    "fix = pd.concat([fix_mc, fix_jwm], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745aadd3",
   "metadata": {},
   "source": [
    "# save to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ef4f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to parquet\n",
    "out_path = Path(__file__).parent / \"../out\"\n",
    "rb.to_parquet(out_path / \"rb_price.parquet\", index=False)\n",
    "fix.to_parquet(out_path / \"fix_price.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
